{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-Z_mowHuhvQ"
      },
      "outputs": [],
      "source": [
        "## Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from nltk.lm.preprocessing import flatten\n",
        "from nltk.util import ngrams\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud\n",
        "import unicodedata\n",
        "import stop_words\n",
        "import spacy\n",
        "from spacy.lang.en import stop_words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from gensim.models import Word2Vec\n",
        "nltk.download('punkt')\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the data and clean/preprocess the text data.\n",
        "df = pd.read_csv('wine-raitngs.csv')\n",
        "df.dropna(inplace=True)\n",
        "df['notes'] = df['notes'].apply(lambda x: unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore'))\n",
        "df['notes'] = df['notes'].str.lower()\n",
        "df['notes'] = df['notes'].str.replace(r'[^\\w\\s]','', regex = True)\n",
        "df['notes'] = df['notes'].str.replace('\\d+', '', regex=True)\n",
        "stop_words = stop_words.STOP_WORDS\n",
        "df['notes'] = df['notes'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "df['notes'].head(5)\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "MbsU3R1rumBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()\n",
        "\n",
        "#create a spot to save the processed text\n",
        "processed_text = []\n",
        "\n",
        "#loop through each item in the list\n",
        "for text in list(df['notes']):\n",
        "  #create tokens\n",
        "  text = nltk.word_tokenize(text)\n",
        "  #stem the words\n",
        "  text = [ps.stem(word = word) for word in text]\n",
        "  #add it to our list\n",
        "  processed_text.append(text)\n",
        "\n",
        "#create a dictionary of the words\n",
        "dictionary = corpora.Dictionary(processed_text)\n",
        "\n",
        "#create a TDM\n",
        "doc_term_matrix = [dictionary.doc2bow(doc) for doc in processed_text]\n",
        "\n",
        "#build model with 50 topics\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus = doc_term_matrix, #TDM\n",
        "                                           id2word = dictionary, #Dictionary\n",
        "                                           num_topics = 50,\n",
        "                                           random_state = 100,\n",
        "                                           update_every = 1,\n",
        "                                           chunksize = 100,\n",
        "                                           passes = 10,\n",
        "                                           alpha = 'auto',\n",
        "                                           per_word_topics = True)"
      ],
      "metadata": {
        "id": "mqz9uUP18pjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vectors and calculate similarities\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "topic_vecs = []\n",
        "\n",
        "for i in range(len(processed_text)):\n",
        "    top_topics = lda_model.get_document_topics(doc_term_matrix[i], minimum_probability=0.0)\n",
        "    topic_vec = [top_topics[i][1] for i in range(50)]\n",
        "    topic_vecs.append(topic_vec)\n",
        "    i = i+1\n",
        "\n",
        "doc_sim = cosine_similarity(topic_vecs)\n",
        "\n",
        "doc_sim_df = pd.DataFrame(doc_sim)\n",
        "doc_sim_df.head()\n",
        "\n",
        "\n",
        "def wine_recommender(wine_name, wines, doc_sims):\n",
        "    # Find wine ID\n",
        "    wine_idx = np.where(wines == wine_name)[0]\n",
        "\n",
        "    # Check if wine exists\n",
        "    if len(wine_idx) == 0:\n",
        "        return f\"Wine '{wine_name}' not found.\"\n",
        "\n",
        "    # Get wine similarities\n",
        "    wine_similarities = doc_sims.iloc[wine_idx[0]].values\n",
        "\n",
        "    # Get top 5 similar wine IDs\n",
        "    similar_wine_idxs = np.argsort(-wine_similarities)[1:6]\n",
        "\n",
        "    # Get top 5 wines\n",
        "    similar_wines = wines[similar_wine_idxs]\n",
        "\n",
        "    # Return the top 5 wines\n",
        "    return similar_wines\n",
        "\n",
        "\n",
        "w1 = wine_recommender(\"14 Hands Hot to Trot Red Blend 2012\",\n",
        "                  df[\"name\"].values,\n",
        "                  doc_sim_df)\n",
        "\n",
        "\n",
        "w2 = wine_recommender(\"A to Z Pinot Gris 2003\",\n",
        "                  df[\"name\"].values,\n",
        "                  doc_sim_df)\n",
        "\n",
        "\n",
        "print(w1)\n",
        "print(w2)"
      ],
      "metadata": {
        "id": "frq5SEVA9JDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "doc_sim_euc = pairwise_distances(topic_vecs, metric = 'euclidean')\n",
        "doc_sim_df_euc = pd.DataFrame(doc_sim_euc)\n",
        "\n",
        "\n",
        "w3 = wine_recommender(\"14 Hands Hot to Trot Red Blend 2012\",\n",
        "                  df[\"name\"].values,\n",
        "                  doc_sim_df_euc)\n",
        "\n",
        "\n",
        "w4 = wine_recommender(\"A to Z Pinot Gris 2003\",\n",
        "                  df[\"name\"].values,\n",
        "                  doc_sim_df_euc)\n",
        "\n",
        "\n",
        "print(w3)\n",
        "print(w4)"
      ],
      "metadata": {
        "id": "KlEv4vimDkgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.Word2Vec(\n",
        "        processed_text,\n",
        "        vector_size=50, #smaller size for smaller data\n",
        "        window=6,\n",
        "        min_count=2,\n",
        "        workers=4)\n",
        "\n",
        "def document_vectorizer(corpus, model, num_features):\n",
        "  vocabulary = set(model.wv.index_to_key)\n",
        "  def average_word_vectors(words, model, vocabulary, num_features):\n",
        "    feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
        "    nwords = 0.\n",
        "    for word in words:\n",
        "      if word in vocabulary:\n",
        "        nwords = nwords + 1.\n",
        "        feature_vector = np.add(feature_vector, model.wv[word])\n",
        "      if nwords:\n",
        "        feature_vector = np.divide(feature_vector, nwords)\n",
        "    return feature_vector\n",
        "  features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
        "                    for tokenized_sentence in corpus]\n",
        "  return np.array(features)\n",
        "\n",
        "avg_wv_features = document_vectorizer(corpus=processed_text,\n",
        "                                                    model=model,\n",
        "                                                     num_features=50)\n",
        "\n",
        "doc_sim_wv = pd.DataFrame(cosine_similarity(avg_wv_features))\n",
        "\n",
        "w5 = wine_recommender(\"14 Hands Hot to Trot Red Blend 2012\",\n",
        "                  df[\"name\"].values,\n",
        "                   doc_sim_wv)\n",
        "\n",
        "\n",
        "w6 = wine_recommender(\"A to Z Pinot Gris 2003\",\n",
        "                  df[\"name\"].values,\n",
        "                   doc_sim_wv)\n",
        "\n",
        "\n",
        "print(w5)\n",
        "print(w6)"
      ],
      "metadata": {
        "id": "lNel-hh4yP90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "\n",
        "\n",
        "doc_sim_euc_wv = pairwise_distances(avg_wv_features, metric = 'euclidean')\n",
        "doc_sim_euc_wv = pd.DataFrame(doc_sim_euc_wv)\n",
        "\n",
        "w7 = wine_recommender(\"14 Hands Hot to Trot Red Blend 2012\",\n",
        "                  df[\"name\"].values,\n",
        "                   doc_sim_euc_wv)\n",
        "\n",
        "\n",
        "w8 = wine_recommender(\"A to Z Pinot Gris 2003\",\n",
        "                  df[\"name\"].values,\n",
        "                   doc_sim_euc_wv)\n",
        "\n",
        "\n",
        "print(w7)\n",
        "print(w8)"
      ],
      "metadata": {
        "id": "Au9pRmn0KQ17"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}